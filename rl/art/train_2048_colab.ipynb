{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ART Training for Text-2048 Environment\n",
        "\n",
        "This notebook trains an agent on the text-2048 environment using:\n",
        "- ART (Agent Reinforcement Training) framework\n",
        "- HUD SDK for MCP agent implementation\n",
        "- Dockerized text-2048 environment\n",
        "- Tasks from HuggingFace dataset\n",
        "\n",
        "**Requirements**: Enable GPU (Runtime → Change runtime type → T4 GPU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install HUD SDK and dependencies\n",
        "!pip install -q hud-python openpipe-art datasets weave openai mcp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Set your API keys and training parameters here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set API keys (optional)\n",
        "# For Colab secrets: Settings → Secrets → Add a new secret\n",
        "# os.environ[\"WANDB_API_KEY\"] = \"\"  # Optional for experiment tracking\n",
        "# os.environ[\"HUD_API_KEY\"] = \"\"    # Optional for HUD telemetry\n",
        "\n",
        "# Model configuration\n",
        "BASE_MODEL = \"Qwen/Qwen2.5-3B-Instruct\"  # 3B model works well on T4\n",
        "MODEL_NAME = \"mcprl-3b-2048\"\n",
        "PROJECT_NAME = \"2048-mcp-rl\"\n",
        "\n",
        "# Training configuration\n",
        "MAX_STEPS = 10  # Max steps per episode\n",
        "TRAINING_CONFIG = {\n",
        "    \"num_training_inputs\": 16,  # Number of training tasks\n",
        "    \"groups_per_step\": 2,       # Trajectory groups per training step\n",
        "    \"num_epochs\": 1,            # Training epochs\n",
        "    \"rollouts_per_group\": 4,    # Rollouts per group\n",
        "    \"learning_rate\": 1e-5,      # Learning rate\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Import Libraries and Define Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "from typing import Awaitable\n",
        "\n",
        "import dotenv\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "import art\n",
        "from art.local import LocalBackend\n",
        "from art.utils import iterate_dataset\n",
        "import weave\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import HUD SDK components\n",
        "from hud.agents import ArtHUDAgent\n",
        "from hud.client import MCPClient\n",
        "from hud.datasets import TaskConfig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "@weave.op()\n",
        "async def rollout(model: art.Model, task_dict: dict) -> art.Trajectory:\n",
        "    \"\"\"Generate one trajectory via ArtHUDAgent.\"\"\"\n",
        "    import hud\n",
        "    \n",
        "    with hud.trace(f\"Art Rollout {task_dict['id']}\", root=True, task_id=task_dict.get(\"id\")):\n",
        "        task_config = TaskConfig(**task_dict)\n",
        "        \n",
        "        mcp_client = MCPClient(task_config.mcp_config)\n",
        "        agent = ArtHUDAgent(model, mcp_client, allowed_tools=[\"move\"])\n",
        "        await agent.initialize()\n",
        "\n",
        "        trace = await agent.run(task_config, max_steps=MAX_STEPS)\n",
        "\n",
        "        traj = art.Trajectory(\n",
        "            messages_and_choices=agent.messages_and_choices,\n",
        "            tools=agent.get_tool_schemas(),\n",
        "            reward=trace.reward,\n",
        "            metadata={\"task\": task_dict},\n",
        "            metrics={\n",
        "                \"task_completed\": trace.done,\n",
        "                \"success\": trace.reward > 0,\n",
        "                \"reward\": trace.reward,\n",
        "                \"ran_out_of_steps\": not trace.done,\n",
        "            },\n",
        "        )\n",
        "\n",
        "        await mcp_client.close()\n",
        "    \n",
        "        return traj.finish()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "\n",
        "# ---- Optional W&B ----\n",
        "WANDB_API_KEY = os.environ.get(\"WANDB_API_KEY\", \"\")\n",
        "if WANDB_API_KEY:\n",
        "    weave.init(PROJECT_NAME)\n",
        "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
        "\n",
        "# ---- Build / register model ----\n",
        "model = art.TrainableModel(\n",
        "    name=MODEL_NAME,\n",
        "    project=PROJECT_NAME,\n",
        "    base_model=BASE_MODEL,\n",
        ")\n",
        "\n",
        "backend = LocalBackend(in_process=True, path=\"./.art\")\n",
        "await model.register(backend)\n",
        "\n",
        "print(\"Model created and registered\")\n",
        "\n",
        "# ---- Generate training scenarios  --------------------------------------------------\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"hud-evals/2048-taskset\", split=\"train\")\n",
        "dataset = list(dataset.shuffle(seed=42))[:TRAINING_CONFIG[\"num_training_inputs\"]]\n",
        "\n",
        "train_iterator = iterate_dataset(\n",
        "    dataset,\n",
        "    groups_per_step=TRAINING_CONFIG[\"groups_per_step\"],\n",
        "    num_epochs=TRAINING_CONFIG[\"num_epochs\"],\n",
        "    initial_step=await model.get_step(),\n",
        ")\n",
        "\n",
        "# ---- Training loop ----\n",
        "for batch in train_iterator:\n",
        "    print(f\"\\n=== Training step {batch.step} ===\")\n",
        "\n",
        "    groups: list[Awaitable[art.TrajectoryGroup]] = []\n",
        "    for task_dict in batch.items:\n",
        "        group = art.TrajectoryGroup(\n",
        "            rollout(model, task_dict)\n",
        "            for _ in range(TRAINING_CONFIG[\"rollouts_per_group\"])\n",
        "        )\n",
        "        groups.append(group)\n",
        "\n",
        "    print(\"Gathering trajectory groups…\")\n",
        "    gathered = await art.gather_trajectory_groups(groups)\n",
        "\n",
        "    # We already have rewards from environment evaluation\n",
        "    await model.train(\n",
        "        gathered,\n",
        "        config=art.TrainConfig(learning_rate=TRAINING_CONFIG[\"learning_rate\"]),\n",
        "    )\n",
        "    print(\"✅ step complete, model checkpoint saved\\n\")\n",
        "\n",
        "print(\"Training finished, checkpoints stored in ./.art/\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
